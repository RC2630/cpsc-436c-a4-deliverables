{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12744904-e177-47af-870a-281aac5367bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# 1: creating initial variables\n",
    "\n",
    "# Create Sagemaker execution role\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "s3_prefix = \"script-mode-workflow\"\n",
    "pickle_s3_prefix = f\"{s3_prefix}/pickle\"\n",
    "pickle_s3_uri = f\"s3://{bucket}/{s3_prefix}/pickle\"\n",
    "pickle_train_s3_uri = f\"{pickle_s3_uri}/train\"\n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0364fdc-ef10-4ed4-8717-93a2ba89730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1: pickling the training data\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def pickleTrainingData():\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    train_data = np.empty((0, 32*32*3))\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        fileNameDataBatch = './cifar-10-batches-py/data_batch_' + str(i)\n",
    "        batch = unpickle(fileNameDataBatch)\n",
    "        train_data = np.vstack((train_data, batch[b'data']))\n",
    "        train_labels += batch[b'labels']\n",
    "\n",
    "    train_labels = np.array(train_labels)\n",
    "    train_data = train_data.reshape(-1, 32, 32, 3) / 255.0\n",
    "    \n",
    "    # !!!!! NOTICE HOW THE DATA IS SAVED !!!!!!\n",
    "    # Will be returned in form of:\n",
    "    # train_label, train_data  = getDataBack()\n",
    "    pickle.dump([train_labels,train_data], open('./train.cnn', 'wb'))\n",
    "    \n",
    "pickleTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417fbd68-7eea-449d-a467-d21bdec83f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2: getting the test data\n",
    "\n",
    "def getTestData():\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    fileNameTestBatch = './cifar-10-batches-py/test_batch'\n",
    "    test_data = unpickle(fileNameTestBatch)[b'data']\n",
    "    test_data = test_data.reshape(-1, 32, 32, 3) / 255.0\n",
    "    test_labels = np.array(unpickle(fileNameTestBatch)[b'labels'])\n",
    "    \n",
    "    num_samples_to_select = 600\n",
    "    random_indices = np.random.choice(test_data.shape[0], num_samples_to_select, replace=False)\n",
    "    selected_test_data = test_data[random_indices]\n",
    "    selected_test_labels = test_labels[random_indices]\n",
    "    \n",
    "    return selected_test_data, selected_test_labels\n",
    "\n",
    "test_data, test_labels = getTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20202405-569f-4399-9646-1ecfea671aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2: uploading training data to S3\n",
    "\n",
    "s3_resource_bucket = boto3.Session().resource(\"s3\").Bucket(bucket)\n",
    "s3_resource_bucket.Object(os.path.join(pickle_s3_prefix, \"train.cnn\")).upload_file(\n",
    "    train_dir + \"/train.cnn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c642df49-ac9b-441c-a900-5a38f039d291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3: creating hyperparameters\n",
    "\n",
    "# This is not required as these values are the defaults:\n",
    "hyperparameters = {\n",
    "    \"copy_X\": True,\n",
    "    \"fit_intercept\": True,\n",
    "    \"normalize\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23c2fbb-cd4f-4b10-a16a-a81ab1cd7848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4: configuring estimator parameters\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Modify this based on your script name !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "entry_point = \"cnnScript.py\"\n",
    "\n",
    "# Modify this based on your instance type / size\n",
    "train_instance_type = \"ml.m5.large\"\n",
    "\n",
    "estimator_parameters = {\n",
    "    \"entry_point\": entry_point,\n",
    "    \"source_dir\": \"script\",\n",
    "    \"framework_version\": \"0.23-1\",\n",
    "    \"py_version\": \"py3\",\n",
    "    \"instance_type\": train_instance_type,\n",
    "    \"instance_count\": 1,\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"role\": role,\n",
    "    \"base_job_name\": \"imagerecognition-model\",\n",
    "}\n",
    "\n",
    "estimator = SKLearn(**estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e177db07-f432-4f04-9adf-ef77334c1f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: imagerecognition-model-2024-11-22-07-38-00-937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-22 07:38:01 Starting - Starting the training job...\n",
      "2024-11-22 07:38:29 Starting - Preparing the instances for training...\n",
      "2024-11-22 07:38:50 Downloading - Downloading input data...\n",
      "2024-11-22 07:39:20 Downloading - Downloading the training image...\n",
      "2024-11-22 07:39:56 Training - Training image download completed. Training in progress..\u001b[34m2024-11-22 07:39:59,882 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-11-22 07:39:59,885 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-22 07:39:59,927 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:00,083 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:00,095 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:00,109 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:00,119 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"copy_X\": true,\n",
      "        \"fit_intercept\": true,\n",
      "        \"normalize\": false\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"imagerecognition-model-2024-11-22-07-38-00-937\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ca-central-1-148761656567/imagerecognition-model-2024-11-22-07-38-00-937/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cnnScript\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cnnScript.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"copy_X\":true,\"fit_intercept\":true,\"normalize\":false}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cnnScript.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cnnScript\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ca-central-1-148761656567/imagerecognition-model-2024-11-22-07-38-00-937/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"copy_X\":true,\"fit_intercept\":true,\"normalize\":false},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"imagerecognition-model-2024-11-22-07-38-00-937\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ca-central-1-148761656567/imagerecognition-model-2024-11-22-07-38-00-937/source/sourcedir.tar.gz\",\"module_name\":\"cnnScript\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cnnScript.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--copy_X\",\"True\",\"--fit_intercept\",\"True\",\"--normalize\",\"False\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_COPY_X=true\u001b[0m\n",
      "\u001b[34mSM_HP_FIT_INTERCEPT=true\u001b[0m\n",
      "\u001b[34mSM_HP_NORMALIZE=false\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python cnnScript.py --copy_X True --fit_intercept True --normalize False\u001b[0m\n",
      "\u001b[34mCollecting Werkzeug==2.0.3\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 289.2/289.2 kB 6.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: Werkzeug\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 0.15.6\n",
      "    Uninstalling Werkzeug-0.15.6:\n",
      "      Successfully uninstalled Werkzeug-0.15.6\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires Werkzeug==0.15.6, but you have werkzeug 2.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed Werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.4\n",
      "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 394.7/394.7 MB 2.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy~=1.19.2 in /miniconda3/lib/python3.7/site-packages (from tensorflow==2.4) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six~=1.15.0 in /miniconda3/lib/python3.7/site-packages (from tensorflow==2.4) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 42.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /miniconda3/lib/python3.7/site-packages (from tensorflow==2.4) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 120.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 21.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 115.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 25.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 462.0/462.0 kB 80.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 106.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 14.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel~=0.35 in /miniconda3/lib/python3.7/site-packages (from tensorflow==2.4) (0.37.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 kB 24.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 10.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /miniconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4) (2.28.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 42.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /miniconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4) (2.0.3)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 22.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /miniconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4) (65.6.3)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 5.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /miniconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4) (6.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4) (3.13.0)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.9/84.9 kB 29.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 42.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=9519009e43fe4d1206c4da925071c72b660119b0cdfd1f48525350cea4cf3ef4\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70835 sha256=0400a4de1e0477dc82a2fe3d16343f6cbbb8204282a25f8e2db446e60adca86c\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\u001b[0m\n",
      "\u001b[34mSuccessfully built termcolor wrapt\u001b[0m\n",
      "\u001b[34mInstalling collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, flatbuffers, tensorboard-data-server, pyasn1, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\u001b[0m\n",
      "\n",
      "2024-11-22 07:40:37 Uploading - Uploading generated training model\u001b[34mSuccessfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-5.5.0 flatbuffers-1.12 gast-0.3.3 google-auth-2.36.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.4.4 oauthlib-3.2.2 opt-einsum-3.3.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:28.707365: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:28.707392: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34mTraining mode\u001b[0m\n",
      "\u001b[34mTraining...\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.490252: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.490508: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.490527: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.490558: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-175-149.ca-central-1.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.490823: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.490964: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.613397: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 110592000 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.726149: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:30.745005: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34mEpoch 1/3\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"cnnScript.py\", line 99, in <module>\n",
      "    model.fit(train_data, train_labels, epochs=3, batch_size=32, validation_split=0.1)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\u001b[0m\n",
      "\u001b[34mValueError: in user code:\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "    /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n",
      "        str(tuple(shape)))\n",
      "    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"cnnScript.py\", line 107, in <module>\n",
      "    trc = traceback.format_exc()\u001b[0m\n",
      "\u001b[34mNameError: name 'traceback' is not defined\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:31,176 sagemaker-containers ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2024-11-22 07:40:31,176 sagemaker-containers ERROR    framework error: \u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n",
      "    entrypoint()\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n",
      "    train(environment.Environment())\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 35, in train\n",
      "    runner_type=runner.ProcessRunnerType)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/entry_point.py\", line 100, in run\n",
      "    wait, capture_error\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 291, in run\n",
      "    cwd=environment.code_dir,\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 208, in check_error\n",
      "    info=extra_info,\u001b[0m\n",
      "\u001b[34msagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mCommand \"/miniconda3/bin/python cnnScript.py --copy_X True --fit_intercept True --normalize False\"\u001b[0m\n",
      "\u001b[34mExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mCommand \"/miniconda3/bin/python cnnScript.py --copy_X True --fit_intercept True --normalize False\"\u001b[0m\n",
      "\n",
      "2024-11-22 07:40:49 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job imagerecognition-model-2024-11-22-07-38-00-937: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n    train(environment.Environment())\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 35, in train\n    runner_type=runner.ProcessRunnerType)\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/entry_point.py\", line 100, in run\n    wait, capture_error\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 291, in run\n    cwd=environment.code_dir,\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 208, in check_error\n    info=extra_info,\nsagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"\"\nCommand \"/miniconda3/bin/python cnnScript.py --copy_X True --fit. Check troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: pickle_train_s3_uri\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# starting the training job\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py:1376\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     forward_to_mlflow_tracking_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1376\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forward_to_mlflow_tracking_server:\n\u001b[1;32m   1378\u001b[0m     log_sagemaker_job_to_mlflow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py:2750\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2748\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2750\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:5945\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5925\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5926\u001b[0m \n\u001b[1;32m   5927\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5943\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5945\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:8547\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   8544\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   8546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 8547\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   8549\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:8611\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   8606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8607\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8608\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8609\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8610\u001b[0m     )\n\u001b[0;32m-> 8611\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8612\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8613\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8614\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8615\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job imagerecognition-model-2024-11-22-07-38-00-937: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n    train(environment.Environment())\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 35, in train\n    runner_type=runner.ProcessRunnerType)\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/entry_point.py\", line 100, in run\n    wait, capture_error\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 291, in run\n    cwd=environment.code_dir,\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 208, in check_error\n    info=extra_info,\nsagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"\"\nCommand \"/miniconda3/bin/python cnnScript.py --copy_X True --fit. Check troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "# 5: running the training job\n",
    "\n",
    "inputs = {\n",
    "    \"train\": pickle_train_s3_uri\n",
    "}\n",
    "\n",
    "# starting the training job\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34d833-a21d-4a83-b215-10ae23c18917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1: getting accuracy of prediction\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "def getAccuracyOfPrediction(cnn_predictions, test_labels):\n",
    "    cnn_predicted_labels = np.argmax(cnn_predictions, axis=1)\n",
    "    accuracy = accuracy_score(test_labels, cnn_predicted_labels)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842e8ff-46e4-43c9-86b0-3bd6db79f924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6: deploying a model to an endpoint\n",
    "\n",
    "sklearn_predictor = estimator.deploy(initial_instance_count=1,\n",
    "                                     instance_type='ml.m5.large',\n",
    "                                     endpoint_name='imagerecognition-endpoint')\n",
    "\n",
    "getAccuracyOfPrediction(sklearn_predictor.predict(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ced2cb-468d-4814-ab4d-38d8eec3a40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7: deleting the endpoint\n",
    "\n",
    "sklearn_predictor.delete_endpoint(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
